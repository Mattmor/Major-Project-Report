%\addcontentsline{toc}{chapter}{Development Process}
\chapter{Original Design}

% You should concentrate on the more important aspects of the design.
% It is essential that an overview is presented before going into detail.
% As well as describing the design adopted it must also explain what other designs were considered and why they were rejected.
% The design should describe what you expected to do, and might also explain areas that you had to revise after some investigation.
% Typically, for an object-oriented design, the discussion will focus on the choice of objects and classes and the allocation of methods to classes.
% The use made of reusable components should be described and their source referenced.
% Particularly important decisions concerning data structures usually affect the architecture of a system and so should be described here.
% How much material you include on detailed design and implementation will depend very much on the nature of the project.
% It should not be padded out. Think about the significant aspects of your system.
% For example, describe the design of the user interface if it is a critical aspect of your system, or provide detail about methods and data structures that are not trivial.
% Do not spend time on long lists of trivial items and repetitive descriptions.
% If in doubt about what is appropriate, speak to your supervisor.
% You should also identify any support tools that you used.
% You should discuss your choice of implementation tools - programming language, compilers, database management system, program development environment, etc.
% Some example sub-sections may be as follows, but the specific sections are for you to define.

\section{Overall architecture}
\paragraph{}
This project had to use ROS\cite{ROS} due to the large robots using this system exclusively and therefore has to be designed with the different parts of the system as different nodes. Details on node designs and interactions are provided below. The general design is to have three separate nodes which interact with each other. These three nodes include a recording node which records the path driven by the robot, a model matching node which matches what the robot LIDAR senses in real time with the data which the recording node gathered and a driving node that takes the resulting match and turns it into driving instructions for the robot.
\paragraph{}
Due to the fact that ICP can be implemented in many ways which affect the speed and accuracy of the match, a pre-existing ICP library is to be used to make the model matching more consistent. Tests were devised and used on a few different ICP libraries to find the best and most customisable library which is explained in the testing section.
\paragraph{}
Extra helper scripts are needed to drive the robot and manually control which model is being matched with the incoming data. Other scripts such as moving the latest recording to the model file and flipping the model so the robot can drive the same path backwards can be made for convenience.

% \begin{itemize}
%   \item The idea is to record the laserscan data while manually driving the route needed and save the data as a model for driving the route automatically.
%   \item Then using this recorded data, compare the incoming laserdata with the model data to figure out the direction to drive.
%   \item Used an ICP library because I didn't want to re-invent the wheel and there are lots out there already.
% \end{itemize}

\section{Tools}
\paragraph{}
The major tools that will be used for this project include ROS\cite{ROS} for running the software on the robot, Gazebo\cite{Gazebo} for simulating the test environment, MRPT\cite{Blanco-Claraco2019} for its ICP library\cite{MRPT-ICP}, catkin\cite{CATKIN} for compilation and TODO: think of more
% \begin{itemize}
%   \item ROS
%   \item MRPT for ICP library
%   \item Compiles using catkin_make
% \end{itemize}

\section{Languages}
\paragraph{}
When using ROS, the two main languages that can be used are Python and C++. Python is easy to use and quick to get running but may take some time with processing whereas C++ is more difficult to use but is more efficient with its processing. C++ is therefore going to be used for the nodes that needed to run at maximum efficiency such as the ICP model matching and the Automatic Driving node and Python is to be used for all the helper scripts and any early prototyping.

\section{Detailed node designs and interactions}
Here is the original detailed node designed as planned from the start. These nodes and interactions can be visualised in a diagram as shown in figure TODO.
\subsection{Recording node}
\paragraph{}
The recording node first has to open a file to write the incoming data to. This file is going to be made within a data/ folder of the root directory for the project. The recording node needs to subscribe to a few different topics one being cmd\_vel and double\_ackermann movement messages that are being sent from any other nodes to control the robot. Due to the need to capture the front LIDAR data, this node also needs to subscribe to the incoming LaserScan data so it is ready to extract the distances when a snapshot is being taken.
\paragraph{}
This node should take snapshots of data at specific times which the user must specify. It should take a snapshot when the user presses a specific button and adds the extracted LaserScan distances to a new line in the file. Any number of snapshots can be taken and should be taken at critical points along the desired path. When at the end of the path the user should take one last snapshot to mark the end of the path and then close the recording node.
\paragraph{}
After recording the full path, the robot can be driven back to the original starting position and the automatic driving part of the system can be launched which will automatically move the robot along the recorded path.

% \begin{itemize}
%   \item Recording:
%   \begin{itemize}
%     \item Picks up movement Messages
%     \item When robot has driven certain distance, take the next 3 laserscan's, average them and write to csv file.
%     \item Distance calculated by using speed given from movement * time since last command.
%   \end{itemize}

\subsection{ICP compare node}
\paragraph{}
The ICP Compare node first has to load the recorded model from the file that the recording node created. When this happens, the number of lines get counted so the number of models is known and this number is published so any nodes that need this information such as the automated driving node knowing when to stop can easily get it. This node has to subscribe to the incoming LaserScan data as this will be the source data to compare against the model which was recorded. This node also subscribes to a state topic which is used to control the model snapshot that the ICP is using as its comparison data. When the node is started, the state always starts from the first state, with that being 0, and gets changed when the subscribed state topic is changed.
\paragraph{}
When the robot publishes the LaserScan data from the front LIDAR, the distance data gets extracted and used as the source to compare against the model with ICP. The ICP algorithm is implemented using MRPT's 2D ICP library which has been tested to be fast enough to process the data in real time. More information about this testing is in the Testing chapter.
% TODO: Other libraries were looked at. NEED TO ADD EARLIER SECTION ABOUT THIS.
\paragraph{}
Each time the LaserScan data gets published, ICP is used on the extracted distances and compared with the selected model's distances. The output from the ICP library should be a 3x1 transformation with an x position translating to if the robot needs to move forwards or backwards and how far, a y position translating to if the robot needs to move sideways and how far and finally an angle in which the robot needs to align itself to. These three values will get used for an ICP direction message which will be published so the automated driving node can use the result to guide the robot along the correct path.

  % \item ICP Compare:
  % \begin{itemize}
  %   \item Load from model file.
  %   \item Starts at snapshot 0.
  %   \item Gets laserscan data from robot and compares to the current snapshot needed.
  %   \item Snapshot number is controlled by other nodes. (such as automated driving)
  %   \item Uses MRPT library, other libraries were looked at.
  %   \item Output from ICP is a 3x1 transformation with an x position, a y position and an angle for rotation.
  %   \item 3x1 transformation is sent to automated driving node.
  % \end{itemize}

\subsection{Automatic driving node}
\paragraph{}
The automated driving node will subscribe to the ICP direction topic so when the directional data gets published, it can be used to guide the robot in the correct direction. This node should also control which snapshot the ICP comparing node is looking at by publishing the value on the state topic which the ICP node is subscribed to. The state should always start from 0 which is the first model and starting position for when the model got recorded. This node is also subscribed to the number of states topic which the ICP node publishes the number of lines in the file, and therefore the number of states that exist in the model. This will get used to determine whether the robot is at the final state and can stop or not.

%   \item Automated Driving:
%   \begin{itemize}
%     \item Takes 3 transformations from ICP node and averages to get rid of anomolies.
%     \item With the average worked out, the transformation gets converted into movement as follows:
%     \begin{itemize}
%       \item Reactionary based system
%       \item x translates to speed.
%       \item y translates to direction to turn if out by a lot.
%       \item angle gets added to direction if its out by a lot.
%     \end{itemize}
%     \item When x is close enough to threashold, advance snapshot by 1.
%   \end{itemize}
% \end{itemize}

\section{Messages}
\paragraph{}
There are three main messages that the system will make use of. The first is the Laserscan message from the built in ROS sensor\_msgs. This message contains a lot of different information but the only part needed for this system are the ranges in which the LIDAR can see and therefore this information gets extracted from the message and either recorded in the recording node or used as the incoming source data for the ICP node.
\paragraph{}
The second message is a custom message that was made for this system. It will be named ICP\_direction and it will contains three floats, one for the x distance, one for the y distance and one for the angle. This message will get created every time the source laserdata gets compared to the current model and is sent to the automated driving node to be turned into driving instructions.
\paragraph{}
The last message is used for controlling the movement of the robbot. There are two different messages that can be used, the main one being the standard cmd\_vel messages which should work on all robots regardless of steering method. The other message is named double\_ackermann and is used for double ackermann steering exclusively which idris uses. Because cmd\_vel messages are more general purpose and the fact that this system is meant to work on a variety of robots, cmd\_vel messages should be the main way to control robots in this system. Double\_ackermann messages can still be used, but they are the less preferred way of using the system.
\paragraph{}
The structure of all three of these messages is shown in figure TODO.

% \begin{itemize}
%   \item Laserscan Message
%   \item ICPDirectional Message
% \end{itemize}

\section{User configuration}
\paragraph{}
This system requires some set-up before the robot can drive the path automatically. First the robot needs to have a clear starting and ending position. The robot also needs to be placed at the starting position in the orientation best suited to get to the end position as the steering is for correction rather than turning.

\paragraph{}
Once the robot is in position, the user has to start the recording node and manually drive the robot along the desired path while choosing good places to take snapshots. When the robot is at the end of its path, the recording node needs to be stopped and the robot needs to be driven back to its starting location. The newly recorded path file needs to be put in the model file that the ICP node will load from and there will be a python script that gets the latest recorded file and uses it as the model.

\paragraph{}
When the robot is roughly at the same starting position, the automated node can be started and the robot will drive along the last recorded path until its completion where it will stop and display a message stating it is at the final state and close enough to stop.
% \begin{itemize}
%   \item Tried to make it easy
%   \item 1. Start recording program and move robot along desired route. Stop program when finished
%   \item 2. Place robot roughly in the same starting position so it can see roughly the same starting things
%   \item 3. Start relivant automated launch file (launch files are named after robot steering systems)
%   \item 4. Watch as the robot drives the same path which was recorded.
% \end{itemize}

\section{Additional scripts}
\paragraph{}
A few additional scripts that help debug the system or help the user automate the process will be used. These scripts include getting the most recent recording and putting the data into the model file ready for launching the automated driving system, flipping the data in the model file so the robot can use the same data to drive the route in reverse, manual control of the robot so the recording part of the system works and manual control of the model states for debugging any issues that occur if a state has been missed.
% \begin{itemize}
%   \item Get latest recording and put it in the model script
%   \item Get the model and flip the values so it can drive the same course in reverse.
%   \item Manual control of robot states
%   \item Manual control of robot
% \end{itemize}

\section{Polish}
\paragraph{}
Because this system is designed to work on all robots, the steering needs to be changed depending on the steering method used by each robot. Therefore, as an extra addition, there needs to be different launch files which contain a parameter for each of the different steering methods. This parameter changes how the program steers when reversing so that all robots steer in the correct direction as this is the biggest difference between steering methods.
% \begin{itemize}
%   \item Because Idris and Argo have different steering, use a param to specify which steering and program chooses weather to reverse steer or not.
%   \item Different launch file for different robots
% \end{itemize}

% Overall - With other ways that were worse so not chosen
% Tools chosen/chosen for me
% Languages
% Detailed node designs/interactions
% Messages
% Additional scripts for ease of use
% Polish
